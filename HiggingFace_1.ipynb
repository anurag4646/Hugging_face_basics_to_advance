{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlf8dGekIAsDbOmWFhBQzO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline function - The pipeline function essentially provides a simple interface for running specific tasks with pre-trained models, such as text generation, sentiment analysis, question answering, and more.**bold text**"
      ],
      "metadata": {
        "id": "OoAz1R_3yafn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQUWB3Ztyhzw",
        "outputId": "33669829-4527-4530-f025-8e4256ec951d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Vxs4gJqxXsy",
        "outputId": "36174839-3973-4011-aadf-e93c6d97acc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998688697814941},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994813799858093}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifiers = pipeline(\"sentiment-analysis\")\n",
        "classifiers([\"I love the hugging face course\",\n",
        "             \"I hate this place so much!\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipelines\n",
        "\n",
        "classifiers = pipeline(\"zero-shot-classification\")\n",
        "classifiers(\n",
        "    \"this course is all about transformers library\",\n",
        "    candidate_labels = [\"education\", \"politics\", \"business\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbgzGtFYzVe6",
        "outputId": "2b0a1b0a-0645-478a-e360-ad17f3337bf0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'this course is all about transformers library',\n",
              " 'labels': ['education', 'business', 'politics'],\n",
              " 'scores': [0.6917900443077087, 0.22207742929458618, 0.08613251894712448]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline(\"text-generation\")\n",
        "\n",
        "generator(\"In this course, will teach you how to\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITXpuCeQ0YYc",
        "outputId": "42d411f8-f5ee-4a8d-b446-020067009b26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, will teach you how to make your own coffee using the \"A\" button. I have started up my own coffee shop to supply my wife and daughter with the raw quality of the coffee, using my traditional methods. But it isn'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model = \"distilgpt2\")\n",
        "\n",
        "generator(\n",
        "    \"In this course, will teach you how to\",\n",
        "    max_length = 30,\n",
        "    num_return_sequences = 2\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6lyd5ns0Rhe",
        "outputId": "6beb980a-1192-45b4-b630-a3c507330351"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In this course, will teach you how to avoid the long term, or the short term,\" Dr. Sathapot of the Institute of International'},\n",
              " {'generated_text': 'In this course, will teach you how to write: The basic fundamentals were first demonstrated in a video game and have moved into a teaching system. Read'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xEU-2mYm2SOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill Mask Pipeline - This pipeline will prridict the missing word in a sentences.**"
      ],
      "metadata": {
        "id": "oojs5zi123_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeQkx4sI3BOA",
        "outputId": "d87914f1-662e-4c6e-b0e5-bfa6a101e006"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.19619794189929962,\n",
              "  'token': 30412,\n",
              "  'token_str': ' mathematical',\n",
              "  'sequence': 'This course will teach you all about mathematical models.'},\n",
              " {'score': 0.04052729159593582,\n",
              "  'token': 38163,\n",
              "  'token_str': ' computational',\n",
              "  'sequence': 'This course will teach you all about computational models.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(\"cat sat on the <mask>.\", top_k = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeGrrRc13gML",
        "outputId": "9ec49b90-20e4-41d0-aff7-bb7646024b3d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.168723002076149,\n",
              "  'token': 16433,\n",
              "  'token_str': ' couch',\n",
              "  'sequence': 'cat sat on the couch.'},\n",
              " {'score': 0.07862888276576996,\n",
              "  'token': 26711,\n",
              "  'token_str': ' sofa',\n",
              "  'sequence': 'cat sat on the sofa.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker(\"Transformer architcture is consist of encoder and <mask>.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wa4FQN3_32_7",
        "outputId": "8e2be522-1a5b-4779-8c18-36482f821d25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.11380074173212051,\n",
              "  'token': 26640,\n",
              "  'token_str': ' compression',\n",
              "  'sequence': 'Transformer architcture is consist of encoder and compression.'},\n",
              " {'score': 0.09564485400915146,\n",
              "  'token': 46133,\n",
              "  'token_str': ' decoding',\n",
              "  'sequence': 'Transformer architcture is consist of encoder and decoding.'},\n",
              " {'score': 0.03949457406997681,\n",
              "  'token': 45278,\n",
              "  'token_str': ' encoding',\n",
              "  'sequence': 'Transformer architcture is consist of encoder and encoding.'},\n",
              " {'score': 0.03395698592066765,\n",
              "  'token': 45182,\n",
              "  'token_str': ' decode',\n",
              "  'sequence': 'Transformer architcture is consist of encoder and decode.'},\n",
              " {'score': 0.025355329737067223,\n",
              "  'token': 42663,\n",
              "  'token_str': ' converter',\n",
              "  'sequence': 'Transformer architcture is consist of encoder and converter.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7B14AYtj4bgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***NER Pipeline - For named entity identification - ***"
      ],
      "metadata": {
        "id": "uoOvDBFL48xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "NER = pipeline(\"ner\", grouped_entities = True)\n",
        "\n",
        "NER(\"My name is Anurag Joshi. I am a Data Scientist at WebMD. India office of WebMD is located in New Mumbai.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrBm5qCr5HL1",
        "outputId": "c207b909-5c8d-4b7e-a67f-d4d856d02840"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.99377215,\n",
              "  'word': 'Anurag Joshi',\n",
              "  'start': 11,\n",
              "  'end': 23},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9973166,\n",
              "  'word': 'WebMD',\n",
              "  'start': 50,\n",
              "  'end': 55},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.99624914,\n",
              "  'word': 'India',\n",
              "  'start': 57,\n",
              "  'end': 62},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9975916,\n",
              "  'word': 'WebMD',\n",
              "  'start': 73,\n",
              "  'end': 78},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9984571,\n",
              "  'word': 'New Mumbai',\n",
              "  'start': 93,\n",
              "  'end': 103}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ce6DsUsu5uCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question-Answering pipeline - ***"
      ],
      "metadata": {
        "id": "pwmaVSLk75HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "QnA = pipeline(\"question-answering\")\n",
        "QnA(\n",
        "    question = \"Where do I work?\",\n",
        "    context = \"My name is Anurag Joshi. I am a Data Scientist at WebMD.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFEdxIgG7_GU",
        "outputId": "b1b47bdf-e7ef-4142-cedc-8665a8b00ad5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.8665696978569031, 'start': 50, 'end': 55, 'answer': 'WebMD'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sath-fhd8aoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarization Pipeline -"
      ],
      "metadata": {
        "id": "mQvksuJs81J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summary = pipeline(\"summarization\")\n",
        "\n",
        "summary(\"\"\"\n",
        "Natural Language Processing (NLP) is a branch of artificial intelligence (AI) that deals with the interaction between computers and human language.\n",
        "It involves developing algorithms and models to understand, interpret, and generate natural language in a way that is meaningful and useful.\n",
        "NLP encompasses various tasks such as language understanding, generation, and analysis. It includes techniques like tokenization, parsing, and semantic analysis\n",
        " to comprehend the structure and meaning of text data. NLP enables machines to extract structured information from unstructured text, perform sentiment analysis,\n",
        "  machine translation, question answering, and text summarization. By leveraging NLP, computers can understand human language inputs, communicate with users through\n",
        "   chatbots, analyze large volumes of text data for insights, and automate tasks that involve processing or generating natural language. NLP has applications in diverse\n",
        "    fields including customer service, healthcare, finance, education, and more, making it a crucial area of research and development in the field of AI.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNoO-a2b85RL",
        "outputId": "ee9cf2cd-0a25-45cd-939a-c7e4f35a652e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Natural Language Processing (NLP) is a branch of artificial intelligence (AI) that deals with the interaction between computers and human language . It involves developing algorithms and models to understand, interpret, and generate natural language in a way that is meaningful and useful . NLP encompasses various tasks such as language understanding, generation, and analysis . It includes techniques like tokenization, parsing, and semantic analysis .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aBuYBEnk9kI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translation Pipeline -"
      ],
      "metadata": {
        "id": "u9Rpq9Et-NhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model = \"Helsinki-NLP/opus-mt-fr-en\")\n",
        "\n",
        "translator(\"Ce cours est produit par Hugging Face.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDnSOLUm-P9o",
        "outputId": "d524bb5f-fa91-4a76-a7ad-c4c70d700bcb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'This course is produced by Hugging Face.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_v6gQkR-5D_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}